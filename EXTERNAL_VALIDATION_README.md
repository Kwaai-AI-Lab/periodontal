# External Validation - User Guide

## Overview

This directory contains scripts to perform external validation of the IBM Dementia Model against observed 2024 prevalence data.

The validation uses a **two-step workflow** that separates model simulation from validation analysis:
1. **Generate** 2024 model results with full population (run once)
2. **Validate** against observed data (run many times as needed)

This approach allows you to use the **full 33M population** (same as IBM_PD_AD.py) while avoiding repeated long-running simulations.

## Quick Start

### Step 1: Generate 2024 Model Results (Run Once)

```bash
python generate_validation_data.py
```

This will:
- Run IBM_PD_AD from 2023 to 2024 with **full population** (33,167,098 people)
- Use the same configuration and methods as IBM_PD_AD.py
- Save results to `validation_results_2024.pkl.gz` (compressed format)
- Take several minutes depending on your system

### Step 2: Perform Validation (Run Anytime)

```bash
python external_validation.py
```

Or use the convenience script:

```bash
python external_validation_fast.py
```

This will:
- Load the pre-computed 2024 results (instant)
- Extract prevalence by age/sex groups
- Compare against observed 2024 data
- Generate calibration plots and validation statistics
- Save outputs to `plots/` directory

## What Gets Generated

After running validation, you'll find:

### Plots (in `plots/` directory)
- `external_validation_f.png` - Female calibration plot
- `external_validation_m.png` - Male calibration plot
- `external_validation_combined.png` - Combined plot for both sexes

### Data Tables
- `plots/validation_comparison_table.csv` - Predicted vs observed comparison

### Validation Statistics
- R² values (goodness of fit)
- Slope coefficients (calibration)
- Age-band specific comparisons

## File Descriptions

### Core Scripts

**`generate_validation_data.py`** - Generates 2024 model results
- Runs IBM_PD_AD to 2024 with full population
- Saves compressed results for validation
- Run this ONCE when you update the model

**`external_validation.py`** - Main validation script
- Loads pre-computed results (or can run fresh)
- Performs validation against observed data
- Generates plots and tables
- Can be run repeatedly with different parameters

**`external_validation_fast.py`** - Convenience wrapper
- Simply loads results and validates
- Includes error checking for missing data
- Recommended for routine validation

### Supporting Files

**`validation_results_2024.pkl.gz`** - Cached model results
- Generated by `generate_validation_data.py`
- Compressed format (uses IBM_PD_AD's built-in compression)
- Contains aggregated prevalence data by age/sex/year

## Observed Data

The validation compares model predictions against these observed 2024 prevalence rates:

| Age Band | Sex | Observed Prevalence |
|----------|-----|---------------------|
| 35-49    | F   | 0.0001             |
| 50-64    | F   | 0.0012             |
| 65-79    | F   | 0.0178             |
| 80+      | F   | 0.1244             |
| 35-49    | M   | 0.0001             |
| 50-64    | M   | 0.0013             |
| 65-79    | M   | 0.0168             |
| 80+      | M   | 0.0910             |

## Advanced Usage

### Running Fresh Without Cached Results

If you want to run the model fresh every time (not recommended):

```python
from external_validation import run_external_validation

results = run_external_validation(
    seed=42,
    save_results=True  # Save for future use
)
```

### Using Different Random Seeds

```python
# Generate data with seed 123
python generate_validation_data.py --seed 123  # (if implemented)

# Or programmatically:
from generate_validation_data import generate_2024_validation_data
generate_2024_validation_data(seed=123)
```

### Custom Save Locations

```python
from external_validation import run_external_validation

results = run_external_validation(
    results_file="path/to/custom_results.pkl.gz",
    save_dir="path/to/custom/plots"
)
```

## Technical Details

### Why Two Steps?

1. **Efficiency**: Run the expensive simulation once, validate many times
2. **Iteration**: Quickly test different validation approaches/plots
3. **Memory**: Uses IBM_PD_AD's proven memory management
4. **Reproducibility**: Exact same results on each validation run

### Memory Usage

The model uses the **same memory approach as IBM_PD_AD.py**:
- Full population: 33,167,098 people
- Memory: ~5-10 GB during simulation
- Cached results: Only ~10-100 KB compressed
- Validation step: Minimal memory (loads aggregated data only)

### Data Storage

The model stores **aggregated prevalence data** only:
- By age band (35-49, 50-64, 65-79, 80+)
- By sex (M, F)
- By year (2024)
- Population counts and dementia case counts

Individual agent data is NOT stored (following IBM_PD_AD's approach).

## Troubleshooting

### "Results file not found"

Run `python generate_validation_data.py` first to create the cached results.

### Model crashes during generation

If `generate_validation_data.py` crashes:
1. Check if `python IBM_PD_AD.py` runs successfully on its own
2. If IBM_PD_AD.py works but generation doesn't, there may be a configuration issue
3. Check available RAM (should be similar to running IBM_PD_AD.py)

### Different results than expected

- Ensure you're using the correct random seed (default: 42)
- Check that `general_config` in IBM_PD_AD.py hasn't changed
- Verify the observed data values are correct

## Workflow Diagram

```
┌─────────────────────────────────────┐
│  generate_validation_data.py        │
│  (Run once after model changes)     │
│                                     │
│  • Loads general_config             │
│  • Runs IBM_PD_AD to 2024           │
│  • Saves results (compressed)       │
└────────────┬────────────────────────┘
             │
             │ Creates: validation_results_2024.pkl.gz
             ↓
┌─────────────────────────────────────┐
│  external_validation.py             │
│  (Run anytime for validation)       │
│                                     │
│  • Loads cached results             │
│  • Compares to observed data        │
│  • Generates plots & statistics     │
└────────────┬────────────────────────┘
             │
             │ Creates: plots/*.png, plots/*.csv
             ↓
┌─────────────────────────────────────┐
│  Validation Outputs                 │
│                                     │
│  • Calibration plots (F/M/combined) │
│  • Comparison table (CSV)           │
│  • R² and slope statistics          │
└─────────────────────────────────────┘
```

## Expected Results

With the current model (seed=42), typical validation results are:

- **Female R² ≈ 0.999** (excellent fit)
- **Male R² ≈ 0.999** (excellent fit)
- **Slopes ≈ 0.8-0.9** (slight underestimation at higher prevalence)

Results may vary with different random seeds or model configurations.
